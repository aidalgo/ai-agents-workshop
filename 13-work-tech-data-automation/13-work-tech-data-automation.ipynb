{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da2986b",
   "metadata": {},
   "source": [
    "# Custom MCP Agent with Data Automation\n",
    "\n",
    "This notebook demonstrates how to create an AI agent that can intelligently ingest and analyze information from collaboration platforms like Microsoft Teams, Outlook, SharePoint, meeting recordings, and other work tech products using a custom Model Context Protocol (MCP) server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8552f76",
   "metadata": {},
   "source": [
    "## Import the Needed Packages\n",
    "\n",
    "We'll import all the necessary libraries for creating our custom Data Automation MCP-enabled agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages from requirements.txt\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba287c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Semantic Kernel imports\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent, FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.connectors.mcp import MCPStdioPlugin\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c484a01",
   "metadata": {},
   "source": [
    "## Setting up Azure OpenAI Connection\n",
    "\n",
    "Configure the Azure OpenAI service using Azure AD authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Option 1: Using API Key (recommended for development)\n",
    "chat_completion_service = AzureChatCompletion(\n",
    "    deployment_name=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\"),\n",
    "    endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Option 2: Using Azure AD Authentication (uncomment to use)\n",
    "# Create Azure credential \n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Create a token provider function\n",
    "def get_azure_ad_token():\n",
    "    \"\"\"Function to get Azure AD token for OpenAI.\"\"\"\n",
    "    token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "    return token.token\n",
    "\n",
    "# chat_completion_service = AzureChatCompletion(\n",
    "#     deployment_name=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\"),\n",
    "#     endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#     api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "#     ad_token=get_azure_ad_token()\n",
    "\n",
    "print(\"Azure OpenAI service configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29260cfc",
   "metadata": {},
   "source": [
    "## Configure Custom MCP Plugin\n",
    "\n",
    "Set up the Model Context Protocol plugin to connect to our custom Data Automation server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MCP Plugin for stdio connection to our custom server\n",
    "# Note: name must follow pattern ^[0-9A-Za-z_]+$\n",
    "mcp_plugin = MCPStdioPlugin(\n",
    "    name=\"data_automation_server\",\n",
    "    command=\"python\",\n",
    "    args=[\"server.py\"],\n",
    "    description=\"Data Automation tools for work collaboration platforms\"\n",
    ")\n",
    "\n",
    "# Create kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "print(f\"MCP Plugin configured for custom Data Automation server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db603a5",
   "metadata": {},
   "source": [
    "## Creating the Custom MCP Agent\n",
    "\n",
    "Create an AI agent with access to our custom Data Automation tools through MCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with MCP plugin via kernel\n",
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service,\n",
    "    kernel=kernel,\n",
    "    name=\"Data-Automation-Agent\",\n",
    "    instructions=\"\"\"\n",
    "    You are a Data Automation assistant that helps analyze and extract insights from \n",
    "    collaboration data across various platforms including Microsoft Teams, Outlook, SharePoint, \n",
    "    Slack, Discord, Zoom, and other work technology platforms.\n",
    "    \n",
    "    Your capabilities include:\n",
    "    - Ingesting chat messages from collaboration platforms\n",
    "    - Analyzing email data from various email platforms\n",
    "    - Processing documents from SharePoint, OneDrive, Google Drive\n",
    "    - Analyzing meeting recordings and transcripts\n",
    "    - Searching across all work tech data using natural language\n",
    "    - Extracting action items and tasks from conversations\n",
    "    - Providing collaboration insights and analytics\n",
    "    \n",
    "    Available MCP tools:\n",
    "    - ingest_chat_messages: Ingest and analyze chat messages from work platforms\n",
    "    - ingest_email_data: Ingest and analyze email data from email platforms\n",
    "    - ingest_documents: Ingest and analyze documents from document platforms\n",
    "    - ingest_meeting_recordings: Ingest and analyze meeting recordings and transcripts\n",
    "    - search_work_data: Search across all ingested work tech data\n",
    "    - get_collaboration_insights: Get insights about collaboration patterns\n",
    "    - extract_action_items: Extract action items and tasks from work data\n",
    "    \n",
    "    When providing analysis:\n",
    "    1. Always show the data you retrieved and explain your reasoning\n",
    "    2. Provide actionable insights and recommendations\n",
    "    3. Highlight key patterns, trends, and important information\n",
    "    4. Suggest follow-up actions when appropriate\n",
    "    5. Maintain confidentiality and professional context\n",
    "    \n",
    "    Be helpful, analytical, and focus on providing valuable business insights from the work tech data.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Created agent: {agent.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b920f06",
   "metadata": {},
   "source": [
    "## Initialize Custom MCP Connection\n",
    "\n",
    "Connect to our custom MCP server and load available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fa005",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def initialize_custom_mcp():\n",
    "    \"\"\"Initialize custom MCP plugin connection and load tools.\"\"\"\n",
    "    try:\n",
    "        # Connect to MCP server\n",
    "        await mcp_plugin.connect()\n",
    "        print(f\"✓ Custom MCP Plugin connected successfully\")\n",
    "        \n",
    "        # Load tools and prompts\n",
    "        await mcp_plugin.load_tools()\n",
    "        print(\"✓ Custom MCP tools loaded\")\n",
    "        \n",
    "        # Add the MCP plugin to the kernel\n",
    "        kernel.add_plugin(mcp_plugin)\n",
    "        print(f\"✓ Custom MCP plugin added to kernel\")\n",
    "        \n",
    "        # Show available functions\n",
    "        print(\"\\nAvailable custom MCP tools:\")\n",
    "        for plugin_name, plugin in kernel.plugins.items():\n",
    "            for function_name, function in plugin.functions.items():\n",
    "                print(f\"  - {function_name}: {function.description}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Custom MCP Plugin setup error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "# Initialize the custom MCP connection\n",
    "mcp_initialized = await initialize_custom_mcp()\n",
    "print(f\"\\nCustom MCP initialization {'successful' if mcp_initialized else 'failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc2ed4",
   "metadata": {},
   "source": [
    "## Agent Interaction Function\n",
    "\n",
    "Create a function to handle user interactions with the agent, displaying both the conversation and function calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_agent(user_input, thread=None):\n",
    "    \"\"\"Chat with the agent and display results with function call details.\"\"\"\n",
    "    \n",
    "    html_output = (\n",
    "        f\"<div style='margin-bottom:10px'>\"\n",
    "        f\"<div style='font-weight:bold'>User:</div>\"\n",
    "        f\"<div style='margin-left:20px'>{user_input}</div></div>\"\n",
    "    )\n",
    "\n",
    "    agent_name = None\n",
    "    full_response: list[str] = []\n",
    "    function_calls: list[str] = []\n",
    "\n",
    "    # Buffer to reconstruct streaming function call\n",
    "    current_function_name = None\n",
    "    argument_buffer = \"\"\n",
    "\n",
    "    try:\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            thread = response.thread\n",
    "            agent_name = response.name\n",
    "            content_items = list(response.items)\n",
    "\n",
    "            for item in content_items:\n",
    "                if isinstance(item, FunctionCallContent):\n",
    "                    if item.function_name:\n",
    "                        current_function_name = item.function_name\n",
    "\n",
    "                    # Accumulate arguments (streamed in chunks)\n",
    "                    if isinstance(item.arguments, str):\n",
    "                        argument_buffer += item.arguments\n",
    "                elif isinstance(item, FunctionResultContent):\n",
    "                    # Finalize any pending function call before showing result\n",
    "                    if current_function_name:\n",
    "                        formatted_args = argument_buffer.strip()\n",
    "                        try:\n",
    "                            parsed_args = json.loads(formatted_args) if formatted_args else {}\n",
    "                            formatted_args = json.dumps(parsed_args)\n",
    "                        except Exception:\n",
    "                            pass  # leave as raw string\n",
    "\n",
    "                        function_calls.append(f\"🔧 Calling function: {current_function_name}({formatted_args})\")\n",
    "                        current_function_name = None\n",
    "                        argument_buffer = \"\"\n",
    "\n",
    "                    function_calls.append(f\"📊 Function Result:\\n{item.result}\")\n",
    "                elif isinstance(item, StreamingTextContent) and item.text:\n",
    "                    full_response.append(item.text)\n",
    "\n",
    "        # Display function calls if any were made\n",
    "        if function_calls:\n",
    "            html_output += (\n",
    "                \"<div style='margin-bottom:10px'>\"\n",
    "                \"<details>\"\n",
    "                \"<summary style='cursor:pointer; font-weight:bold; color:#0066cc;'>MCP Tool Calls (click to expand)</summary>\"\n",
    "                \"<div style='margin:10px; padding:10px; background-color:#f8f8f8; \"\n",
    "                \"border:1px solid #ddd; border-radius:4px; white-space:pre-wrap; font-size:14px; color:#333;'>\"\n",
    "                f\"{chr(10).join(function_calls)}\"\n",
    "                \"</div></details></div>\"\n",
    "            )\n",
    "\n",
    "        html_output += (\n",
    "            \"<div style='margin-bottom:20px'>\"\n",
    "            f\"<div style='font-weight:bold'>{agent_name or 'Assistant'}:</div>\"\n",
    "            f\"<div style='margin-left:20px; white-space:pre-wrap'>{''.join(full_response)}</div></div><hr>\"\n",
    "        )\n",
    "\n",
    "        display(HTML(html_output))\n",
    "        return thread\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during agent execution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return thread\n",
    "\n",
    "print(\"Agent interaction function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23108fa8",
   "metadata": {},
   "source": [
    "## Test the Data Automation Agent\n",
    "\n",
    "Now let's test our custom MCP-enabled agent with some data automation questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions for the Data Automation agent\n",
    "test_questions = [\n",
    "    \"Ingest all chat messages from Microsoft Teams and provide a sentiment analysis\",\n",
    "    \"What are the current collaboration insights across all platforms?\",\n",
    "    \"Extract action items from all work tech data sources\"\n",
    "]\n",
    "\n",
    "# Run the conversation\n",
    "thread = None\n",
    "for question in test_questions:\n",
    "    thread = await chat_with_agent(question, thread)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")  # Separator between questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a19b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis question\n",
    "detailed_question = \"Search for any mentions of 'API' or 'database' across all work tech platforms and provide a comprehensive analysis\"\n",
    "thread = await chat_with_agent(detailed_question, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b65f285",
   "metadata": {},
   "source": [
    "## Interactive Chat\n",
    "\n",
    "Use this cell to ask your own questions to the Data Automation agent. The agent will use the custom MCP tools to provide insights from work collaboration data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive chat - modify the question below\n",
    "user_question = \"What are the most discussed topics in our organization and which platforms are being used most?\"\n",
    "\n",
    "# Use the existing thread to maintain conversation context\n",
    "thread = await chat_with_agent(user_question, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f0f682",
   "metadata": {},
   "source": [
    "## Custom Data Analysis\n",
    "\n",
    "Create your own custom query to test the agent's data analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom query - replace with your own question\n",
    "custom_question = \"Analyze our meeting patterns and extract any follow-up actions from recent meetings\"\n",
    "\n",
    "thread = await chat_with_agent(custom_question, thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e120cfb",
   "metadata": {},
   "source": [
    "## View Available MCP Tools\n",
    "\n",
    "Let's examine what tools are available from our custom MCP server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd12f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display available tools and their descriptions\n",
    "print(\"Available Custom MCP Tools:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for plugin_name, plugin in kernel.plugins.items():\n",
    "    print(f\"\\nPlugin: {plugin_name}\")\n",
    "    for function_name, function in plugin.functions.items():\n",
    "        print(f\"  🔧 {function_name}\")\n",
    "        print(f\"     Description: {function.description}\")\n",
    "        print(f\"     Parameters: {[param.name for param in function.parameters]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d93d042",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Clean up the MCP connection when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b42928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up MCP connection\n",
    "try:\n",
    "    await mcp_plugin.close()\n",
    "    print(\"✓ Custom MCP Plugin closed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error closing custom MCP plugin: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
