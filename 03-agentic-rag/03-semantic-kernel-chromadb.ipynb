{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Kernel Tool Use Example\n",
    "\n",
    "This document provides an overview and explanation of the code used to create a Semantic Kernel-based tool that integrates with ChromaDB for Retrieval-Augmented Generation (RAG). The example demonstrates how to build an AI agent that retrieves travel documents from a ChromaDB collection, augments user queries with semantic search results, and streams detailed travel recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLite Version Fix\n",
    "If you encounter the error:\n",
    "```\n",
    "RuntimeError: Your system has an unsupported version of sqlite3. Chroma requires sqlite3 >= 3.35.0\n",
    "```\n",
    "\n",
    "Uncomment this code block at the start of your notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pysqlite3-binary (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pysqlite3-binary\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'pysqlite3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall pysqlite3-binary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqlite3\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpysqlite3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pysqlite3'"
     ]
    }
   ],
   "source": [
    "# %pip install pysqlite3-binary\n",
    "# import sys\n",
    "# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages\n",
    "The following code imports the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import chromadb\n",
    "from typing import Annotated, TYPE_CHECKING\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents import FunctionCallContent,FunctionResultContent, StreamingTextContent\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from chromadb.api.models.Collection import Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Semantic Kernel and AI Service\n",
    "\n",
    "A Semantic Kernel instance is created and configured with an asynchronous OpenAI chat completion service. The service is added to the kernel for use in generating responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Option 1: Using API Key (recommended for development)\n",
    "chat_completion_service = AzureChatCompletion(\n",
    "    deployment_name=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\"),\n",
    "    endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "# Option 2: Using Azure AD Authentication (uncomment to use)\n",
    "# Create Azure credential \n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Create a token provider function\n",
    "def get_azure_ad_token():\n",
    "    \"\"\"Function to get Azure AD token for OpenAI.\"\"\"\n",
    "    token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "    return token.token\n",
    "\n",
    "# chat_completion_service = AzureChatCompletion(\n",
    "#     deployment_name=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\"),\n",
    "#     endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "#     api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\"),\n",
    "#     ad_token=get_azure_ad_token()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Prompt Plugin\n",
    "\n",
    "The PromptPlugin is a native plugin that defines a function to build an augmented prompt using retrieval context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptPlugin:\n",
    "    \"\"\"\n",
    "    This plugin implements Retrieval-Augmented Generation (RAG) by combining:\n",
    "    1. Information retrieval from ChromaDB vector database\n",
    "    2. Prompt augmentation with retrieved context\n",
    "    3. Generation using the augmented prompt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, collection: \"Collection\"):\n",
    "        # Store reference to ChromaDB collection for semantic search\n",
    "        self.collection = collection\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"build_augmented_prompt\",\n",
    "        description=\"Build an augmented prompt using retrieval context.\"\n",
    "    )\n",
    "    def build_augmented_prompt(self, query: str, retrieval_context: str) -> str:\n",
    "        \"\"\"\n",
    "        RAG AUGMENTATION\n",
    "        Takes the user's original query and retrieved context, then creates\n",
    "        a structured prompt that instructs the LLM to base its response on\n",
    "        the provided context rather than just its training data.\n",
    "        \n",
    "        This is the \"Augmented\" part of RAG - we're augmenting the user's\n",
    "        query with relevant retrieved information.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f\"Retrieved Context:\\n{retrieval_context}\\n\\n\"\n",
    "            f\"User Query: {query}\\n\\n\"\n",
    "            \"Based ONLY on the above context, please provide your answer.\"\n",
    "        )\n",
    "    \n",
    "    @kernel_function(name=\"retrieve_context\", description=\"Retrieve context from the database.\")\n",
    "    def get_retrieval_context(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        RAG Step 1: RETRIEVAL\n",
    "        This function performs semantic search in the ChromaDB vector database:\n",
    "        \n",
    "        1. Takes the user's query as input\n",
    "        2. Uses ChromaDB's built-in embedding model to convert the query to vectors\n",
    "        3. Searches for the most similar documents in the vector database\n",
    "        4. Returns the top 2 most relevant documents with their metadata\n",
    "        \n",
    "        This is the \"Retrieval\" part of RAG - we're retrieving relevant\n",
    "        information from our knowledge base before generating a response.\n",
    "        \"\"\"\n",
    "        # Perform semantic search in ChromaDB\n",
    "        # ChromaDB automatically converts the query text to embeddings and\n",
    "        # finds the most semantically similar documents\n",
    "        results = self.collection.query(\n",
    "            query_texts=[query],              # Convert user query to vector embedding\n",
    "            include=[\"documents\", \"metadatas\"], # Return both text content and metadata\n",
    "            n_results=2                       # Retrieve top 2 most similar documents\n",
    "        )\n",
    "        \n",
    "        # Process and format the retrieved results\n",
    "        context_entries = []\n",
    "        if results and results.get(\"documents\") and results[\"documents\"][0]:\n",
    "            # Combine each document with its metadata for richer context\n",
    "            for doc, meta in zip(results[\"documents\"][0], results[\"metadatas\"][0]):\n",
    "                context_entries.append(f\"Document: {doc}\\nMetadata: {meta}\")\n",
    "        \n",
    "        # Return formatted context or fallback message\n",
    "        # This retrieved context will be used in the augmentation step\n",
    "        return \"\\n\\n\".join(context_entries) if context_entries else \"No retrieval context found.\"\n",
    "\n",
    "# RAG Process Summary:\n",
    "# 1. RETRIEVAL: get_retrieval_context() searches ChromaDB for relevant documents\n",
    "# 2. AUGMENTATION: build_augmented_prompt() combines query + retrieved context  \n",
    "# 3. GENERATION: The LLM generates a response based on the augmented prompt\n",
    "#\n",
    "# This approach ensures the AI's responses are grounded in your specific\n",
    "# knowledge base rather than just relying on its training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Weather Information Plugin\n",
    "\n",
    "The WeatherInfoPlugin is a native plugin that provides temperature information for specific travel destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherInfoPlugin:\n",
    "    \"\"\"A Plugin that provides the average temperature for a travel destination.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Dictionary of destinations and their average temperatures\n",
    "        self.destination_temperatures = {\n",
    "            \"maldives\": \"82°F (28°C)\",\n",
    "            \"swiss alps\": \"45°F (7°C)\",\n",
    "            \"african safaris\": \"75°F (24°C)\"\n",
    "        }\n",
    "\n",
    "    @kernel_function(description=\"Get the average temperature for a specific travel destination.\")\n",
    "    def get_destination_temperature(self, destination: str) -> Annotated[str, \"Returns the average temperature for the destination.\"]:\n",
    "        \"\"\"Get the average temperature for a travel destination.\"\"\"\n",
    "        # Normalize the input destination (lowercase)\n",
    "        normalized_destination = destination.lower()\n",
    "\n",
    "        # Look up the temperature for the destination\n",
    "        if normalized_destination in self.destination_temperatures:\n",
    "            return f\"The average temperature in {destination} is {self.destination_temperatures[normalized_destination]}.\"\n",
    "        else:\n",
    "            return f\"Sorry, I don't have temperature information for {destination}. Available destinations are: Maldives, Swiss Alps, and African safaris.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Destinations Information Plugin\n",
    "\n",
    "The DestinationsPlugin is a native plugin that provides detailed information about popular travel destinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DestinationsPlugin:\n",
    "    # Destination data store with rich details about popular travel locations\n",
    "    DESTINATIONS = {\n",
    "        \"maldives\": {\n",
    "            \"name\": \"The Maldives\",\n",
    "            \"description\": \"An archipelago of 26 atolls in the Indian Ocean, known for pristine beaches and overwater bungalows.\",\n",
    "            \"best_time\": \"November to April (dry season)\",\n",
    "            \"activities\": [\"Snorkeling\", \"Diving\", \"Island hopping\", \"Spa retreats\", \"Underwater dining\"],\n",
    "            \"avg_cost\": \"$400-1200 per night for luxury resorts\"\n",
    "        },\n",
    "        \"swiss alps\": {\n",
    "            \"name\": \"The Swiss Alps\",\n",
    "            \"description\": \"Mountain range spanning across Switzerland with picturesque villages and world-class ski resorts.\",\n",
    "            \"best_time\": \"December to March for skiing, June to September for hiking\",\n",
    "            \"activities\": [\"Skiing\", \"Snowboarding\", \"Hiking\", \"Mountain biking\", \"Paragliding\"],\n",
    "            \"avg_cost\": \"$250-500 per night for alpine accommodations\"\n",
    "        },\n",
    "        \"safari\": {\n",
    "            \"name\": \"African Safari\",\n",
    "            \"description\": \"Wildlife viewing experiences across various African countries including Kenya, Tanzania, and South Africa.\",\n",
    "            \"best_time\": \"June to October (dry season) for optimal wildlife viewing\",\n",
    "            \"activities\": [\"Game drives\", \"Walking safaris\", \"Hot air balloon rides\", \"Cultural village visits\"],\n",
    "            \"avg_cost\": \"$400-800 per person per day for luxury safari packages\"\n",
    "        },\n",
    "        \"bali\": {\n",
    "            \"name\": \"Bali, Indonesia\",\n",
    "            \"description\": \"Island paradise known for lush rice terraces, beautiful temples, and vibrant culture.\",\n",
    "            \"best_time\": \"April to October (dry season)\",\n",
    "            \"activities\": [\"Surfing\", \"Temple visits\", \"Rice terrace trekking\", \"Yoga retreats\", \"Beach relaxation\"],\n",
    "            \"avg_cost\": \"$100-500 per night depending on accommodation type\"\n",
    "        },\n",
    "        \"santorini\": {\n",
    "            \"name\": \"Santorini, Greece\",\n",
    "            \"description\": \"Stunning volcanic island with white-washed buildings and blue domes overlooking the Aegean Sea.\",\n",
    "            \"best_time\": \"Late April to early November\",\n",
    "            \"activities\": [\"Sunset watching in Oia\", \"Wine tasting\", \"Boat tours\", \"Beach hopping\", \"Ancient ruins exploration\"],\n",
    "            \"avg_cost\": \"$200-600 per night for caldera view accommodations\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_destination_info\",\n",
    "        description=\"Provides detailed information about specific travel destinations.\"\n",
    "    )\n",
    "    def get_destination_info(self, query: str) -> str:\n",
    "        # Find which destination is being asked about\n",
    "        query_lower = query.lower()\n",
    "        matching_destinations = []\n",
    "\n",
    "        for key, details in DestinationsPlugin.DESTINATIONS.items():\n",
    "            if key in query_lower or details[\"name\"].lower() in query_lower:\n",
    "                matching_destinations.append(details)\n",
    "\n",
    "        if not matching_destinations:\n",
    "            return (f\"User Query: {query}\\n\\n\"\n",
    "                    f\"I couldn't find specific destination information in our database. \"\n",
    "                    f\"Please use the general retrieval system for this query.\")\n",
    "\n",
    "        # Format destination information\n",
    "        destination_info = \"\\n\\n\".join([\n",
    "            f\"Destination: {dest['name']}\\n\"\n",
    "            f\"Description: {dest['description']}\\n\"\n",
    "            f\"Best time to visit: {dest['best_time']}\\n\"\n",
    "            f\"Popular activities: {', '.join(dest['activities'])}\\n\"\n",
    "            f\"Average cost: {dest['avg_cost']}\" for dest in matching_destinations\n",
    "        ])\n",
    "\n",
    "        return (f\"Destination Information:\\n{destination_info}\\n\\n\"\n",
    "                f\"User Query: {query}\\n\\n\"\n",
    "                \"Based on the above destination details, provide a helpful response \"\n",
    "                \"that addresses the user's query about this location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up ChromaDB\n",
    "\n",
    "To facilitate Retrieval-Augmented Generation, a persistent ChromaDB client is instantiated and a collection named `\"travel_documents\"` is created (or retrieved if it exists). This collection is then populated with sample travel documents and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Create or connect to a persistent ChromaDB vector database\n",
    "# ChromaDB automatically handles:\n",
    "# - Converting text documents to vector embeddings using a default embedding model\n",
    "# - Storing these embeddings in a searchable vector index\n",
    "# - Persisting the database to disk for reuse across sessions\n",
    "collection = chromadb.PersistentClient(path=\"./chroma_db\").create_collection(\n",
    "    name=\"travel_documents\",                    # Unique collection name for our travel knowledge base\n",
    "    metadata={\"description\": \"travel_service\"}, # Optional metadata about this collection\n",
    "    get_or_create=True,                        # Reuse existing collection if it already exists\n",
    ")\n",
    "\n",
    "# STEP 2: Define our knowledge base documents\n",
    "# These are the documents that will be available for retrieval during RAG\n",
    "# In a real application, these might come from:\n",
    "# - PDF files, web scraping, databases, APIs, etc.\n",
    "# - Company documentation, FAQs, product manuals, etc.\n",
    "documents = [\n",
    "    \"Contoso Travel offers luxury vacation packages to exotic destinations worldwide.\",\n",
    "    \"Our premium travel services include personalized itinerary planning and 24/7 concierge support.\",\n",
    "    \"Contoso's travel insurance covers medical emergencies, trip cancellations, and lost baggage.\",\n",
    "    \"Popular destinations include the Maldives, Swiss Alps, and African safaris.\",\n",
    "    \"Contoso Travel provides exclusive access to boutique hotels and private guided tours.\",\n",
    "]\n",
    "\n",
    "# STEP 3: Add documents to the vector database\n",
    "# ChromaDB will automatically:\n",
    "# 1. Convert each document text into high-dimensional vector embeddings\n",
    "# 2. Store these vectors in an efficient searchable index\n",
    "# 3. Associate each vector with its original text and metadata\n",
    "collection.add(\n",
    "    documents=documents,                                           # The actual text content\n",
    "    ids=[f\"doc_{i}\" for i in range(len(documents))],             # Unique ID for each document\n",
    "    metadatas=[{\"source\": \"training\", \"type\": \"explanation\"} for _ in documents]  # Metadata for each doc\n",
    ")\n",
    "\n",
    "# What happens behind the scenes:\n",
    "# - Each document is processed by an embedding model (like sentence-transformers)\n",
    "# - Text is converted to a vector of numbers (e.g., 384 or 768 dimensions)\n",
    "# - Similar documents will have similar vector representations\n",
    "# - When we query later, ChromaDB will find documents with vectors most similar to the query vector\n",
    "#\n",
    "# This vector database is now ready for semantic search during RAG retrieval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatCompletionAgent(\n",
    "    service=chat_completion_service,\n",
    "    plugins=[DestinationsPlugin(), WeatherInfoPlugin(), PromptPlugin(collection)],\n",
    "    name=\"TravelAgent\",\n",
    "    instructions=\"\"\"You are a travel agent assistant. For ANY travel-related query:\n",
    "\n",
    "1. ALWAYS first call 'retrieve_context' to get relevant information from the knowledge base\n",
    "2. ALWAYS then call 'build_augmented_prompt' with the user's query and the retrieved context\n",
    "3. Use the augmented prompt to provide your final response\n",
    "\n",
    "For temperature questions, also call 'get_destination_temperature'.\n",
    "For destination details, also call 'get_destination_info' if applicable.\n",
    "\n",
    "Never say 'I have no context for that' - always attempt to retrieve context first.\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Agent with Streaming Chat History\n",
    "The main asynchronous loop creates a chat history for the conversation and, for each user input, first adds the augmented prompt (as a system message) to the chat history so that the agent sees the retrieval context. The user message is also added, and then the agent is invoked using streaming. The output is printed as it streams in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom:10px'><div style='font-weight:bold'>User:</div><div style='margin-left:20px'>Can you explain Contoso's travel insurance coverage?</div></div><div style='margin-bottom:20px'><div style='font-weight:bold'>TravelAgent:</div><div style='margin-left:20px; white-space:pre-wrap'>Contoso's travel insurance provides coverage for medical emergencies, trip cancellations, and lost baggage.</div></div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom:10px'><div style='font-weight:bold'>User:</div><div style='margin-left:20px'>What is the average temperature of the Maldives?</div></div><div style='margin-bottom:20px'><div style='font-weight:bold'>TravelAgent:</div><div style='margin-left:20px; white-space:pre-wrap'>The average temperature in the Maldives is 82°F (28°C).</div></div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='margin-bottom:10px'><div style='font-weight:bold'>User:</div><div style='margin-left:20px'>What is a good cold destination offered by Contoso and what is it average temperature?</div></div><div style='margin-bottom:20px'><div style='font-weight:bold'>TravelAgent:</div><div style='margin-left:20px; white-space:pre-wrap'>It seems Contoso Travel offers luxury vacation packages to exotic destinations worldwide, but there is no specific mention of cold destinations within the provided context. Would you like me to search for a popular cold destination separately?</div></div><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async def main():\n",
    "    thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "    user_inputs = [\n",
    "        \"Can you explain Contoso's travel insurance coverage?\",\n",
    "        \"What is the average temperature of the Maldives?\",\n",
    "        \"What is a good cold destination offered by Contoso and what is it average temperature?\",\n",
    "    ]\n",
    "\n",
    "    for user_input in user_inputs:\n",
    "        html_output = (\n",
    "            f\"<div style='margin-bottom:10px'>\"\n",
    "            f\"<div style='font-weight:bold'>User:</div>\"\n",
    "            f\"<div style='margin-left:20px'>{user_input}</div></div>\"\n",
    "        )\n",
    "\n",
    "        agent_name = None\n",
    "        full_response: list[str] = []\n",
    "        function_calls: list[str] = []\n",
    "\n",
    "        # Buffer to reconstruct streaming function call\n",
    "        current_function_name = None\n",
    "        argument_buffer = \"\"\n",
    "\n",
    "        async for response in agent.invoke_stream(\n",
    "            messages=user_input,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            thread = response.thread\n",
    "            agent_name = response.name\n",
    "            content_items = list(response.items)\n",
    "\n",
    "            for item in content_items:\n",
    "                if isinstance(item, FunctionCallContent):\n",
    "                    if item.function_name:\n",
    "                        current_function_name = item.function_name\n",
    "\n",
    "                    # Accumulate arguments (streamed in chunks)\n",
    "                    if isinstance(item.arguments, str):\n",
    "                        argument_buffer += item.arguments\n",
    "                elif isinstance(item, FunctionResultContent):\n",
    "                    # Finalize any pending function call before showing result\n",
    "                    if current_function_name:\n",
    "                        formatted_args = argument_buffer.strip()\n",
    "                        try:\n",
    "                            parsed_args = json.loads(formatted_args)\n",
    "                            formatted_args = json.dumps(parsed_args)\n",
    "                        except Exception:\n",
    "                            pass  # leave as raw string\n",
    "\n",
    "                        function_calls.append(f\"Calling function: {current_function_name}({formatted_args})\")\n",
    "                        current_function_name = None\n",
    "                        argument_buffer = \"\"\n",
    "\n",
    "                    function_calls.append(f\"\\nFunction Result:\\n\\n{item.result}\")\n",
    "                elif isinstance(item, StreamingTextContent) and item.text:\n",
    "                    full_response.append(item.text)\n",
    "\n",
    "        if function_calls:\n",
    "            html_output += (\n",
    "                \"<div style='margin-bottom:10px'>\"\n",
    "                \"<details>\"\n",
    "                \"<summary style='cursor:pointer; font-weight:bold; color:#0066cc;'>Function Calls (click to expand)</summary>\"\n",
    "                \"<div style='margin:10px; padding:10px; background-color:#f8f8f8; \"\n",
    "                \"border:1px solid #ddd; border-radius:4px; white-space:pre-wrap; font-size:14px; color:#333;'>\"\n",
    "                f\"{chr(10).join(function_calls)}\"\n",
    "                \"</div></details></div>\"\n",
    "            )\n",
    "\n",
    "        html_output += (\n",
    "            \"<div style='margin-bottom:20px'>\"\n",
    "            f\"<div style='font-weight:bold'>{agent_name or 'Assistant'}:</div>\"\n",
    "            f\"<div style='margin-left:20px; white-space:pre-wrap'>{''.join(full_response)}</div></div><hr>\"\n",
    "        )\n",
    "\n",
    "        display(HTML(html_output))\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
